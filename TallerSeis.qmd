---
title: "Taller Sexto"
format: html
editor: visual
---



```{r, echo=FALSE, message=FALSE}
library(readxl)
library(dplyr)
library(factoextra)
library(clusterCrit)
library(NbClust)
library(ggplot2)
library(openxlsx)
library(knitr)
library(ggsci)
library(NbClust)
library(kableExtra)
library(DT)
```



## Punto 1

El indicador Scimago establece un ranking universitario bas치ndose en la calidad de las publicaciones que estas realicen, el archivo que se utiliza para este ejercicio contiene datos de 149 Universidades Latinas y 11 indicadores de Scimago: SC.Lac.Ranking , SC.Ibe.Ranking SC.Co.Ranking, SC.Productividad, SC.Colaboracion.Interciol, SC.Impacto.normalizado, SC.Publicaciones.de.alta.calidad, SC.Indice.de.especializacion, SC.Indice.de.excelencia, SC.Liderazgo.cientifico, SC.Excelencia.con.liderazgo.

En la siguiente tabla se muestran algunas universidades con los valores de estos indicadores estandarizados para hacer los an치lisis correctamente

```{r,echo=FALSE}
options(warn = -1)  # Suprime las advertencias
suppressPackageStartupMessages({
  library(readxl)
  library(dplyr)
  library(factoextra)
  library(clusterCrit)
  library(NbClust)
  library(ggplot2)
  library(openxlsx)
  library(knitr)
  library(kableExtra)
  library(DT)
})

# 游늷 1. Cargar datos desde Excel
df <- read.csv2("C:/Users/fabia/OneDrive - Universidad Nacional de Colombia/UNAL/Descriptiva multivariada/Talleres/Recopilaci칩n/Bases de datos/r14_Sci_Qs_Webometrics.csv", sep = ";")

# 游늷 2. Reemplazar NA por 0 en las columnas num칠ricas
df <- df %>% mutate(across(where(is.numeric), ~ifelse(is.na(.), 0, .)))

# 游늷 3. Seleccionar solo las columnas que comienzan con "SC" y las columnas "Pais" y "UniPais"
df_clustering <- df %>% select(Pais, UniPais, starts_with("SC"))

# 游늷 4. Estandarizar los datos num칠ricos
df_scaled <- df_clustering %>% select(starts_with("SC")) %>% scale()

# 游늷 5. Crear un nuevo dataframe con los datos estandarizados y las columnas categ칩ricas
df_final <- df_clustering %>%
  select(Pais, UniPais) %>%
  bind_cols(as.data.frame(df_scaled))

# 游늷 6. Mostrar las primeras filas en tabla con formato bonito
kable(head(df_final), format = "html") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))
```

**C치lculo del indicador de Calinski-Harabasz para decidir el n칰mero de grupos:**

Los valores del 칤ndice de Carlinski - Harabasz en la siguiente tabla y la gr치fica indican que el n칰mero de grupos 칩ptimo se obtiene donde el CH~k~ toma su mayor valor en este caso es de 3.

```{r,echo=FALSE}
# 游늷 7. Determinar el n칰mero 칩ptimo de clusters usando el 칤ndice de Cali켻ski-Harabasz
set.seed(42)
res <- NbClust(df_scaled, distance = "euclidean", min.nc = 2, max.nc = 10, method = "kmeans", index = "ch")

# Extraer el n칰mero 칩ptimo de clusters
k_optimo <- as.numeric(res$Best.nc[1])

# Extraer valores del 칤ndice para cada K
ch_values <- res$All.index
k_values <- 2:10

# Crear un dataframe con los valores de K y sus respectivos 칤ndices CH
tabla_ch <- data.frame(Clusters = k_values, CH_Index = ch_values)

# Mostrar la tabla en la consola
print(tabla_ch)
```

```{r,echo=FALSE}
# 游늷 8. Gr치fico del 칤ndice de Cali켻ski-Harabasz
plot(k_values, ch_values, type = "b", pch = 19, col = "blue",
     xlab = "N칰mero de Clusters (K)", ylab = "칈ndice de Cali켻ski-Harabasz",
     main = "Selecci칩n de K usando CH Index",
     xaxt = "n")

axis(1, at = k_values, labels = k_values) 

text(k_values, ch_values, labels = k_values, pos = 3, col = "red", cex = 0.8)

# 游늷 9. Aplicar K-means con el n칰mero 칩ptimo de clusters
set.seed(42)
final_kmeans <- kmeans(df_scaled, centers = k_optimo, nstart = 25)

```

En la siguiente tabla se muestran los 3 grupos que produce este agrupamiento, donde destaca el grupo 2 que solo cuenta con 17 universidades, una de las razones para que esto pase es porque aunque estan bien posicionadas no son las top, teniendo un menor producci칩n cient칤fica que el grupo 3 (compuesta por las universidades top con alta producci칩n cienti칤fica y colaboraci칩n internacional) pero significativa y mayor que el grupo 1, pues, en este ultimo grupo se encuentran universidades que tienen un menor impacto en la producci칩n cient칤fica y menor 칠nfasis en investigaci칩n

```{r,echo=FALSE}
# 游늷 10. Agregar los clusters al dataframe original
df_final$Cluster <- final_kmeans$cluster

# 游늷 11. Crear tablas de resumen
tabla_Unipaises <- df_final %>% select(UniPais, Cluster)
tabla_paises <- df_final %>% select(Pais, Cluster)

cat("Tabla: Universidades y sus Clusters\n")
datatable(tabla_Unipaises)

cat("Tabla: Pa칤ses y sus Clusters\n")
datatable(tabla_paises)

```

**Tipificaci칩n de los grupos sugeridos por el 칤ndice de CH por los promedios de las variables:**

Los promedios de las variables para los 3 grupos sugeridos por el 칤ndice de Calinski-Harabasz con el algoritmo K medias se muestran en la siguiente tabla ordenadas por el SC.Lack.Ranking.

```{r,echo=FALSE}
# 游늷 8. Agregar los clusters al dataframe original
df_clustering$Cluster <- final_kmeans$cluster

# 游늷 9. Crear tablas de resumen

# Tabla con pa칤ses y su cluster asignado
tabla_Unipaises <- df_clustering %>% select(UniPais, Cluster)
tabla_paises <- df_clustering %>% select(Pais, Cluster)

library(DT)

# 游늷 12. Promedios por cluster
resumen_media <- df_final %>%
  group_by(Cluster) %>%
  summarise(across(starts_with("SC"), mean, .names = "{.col}"))

datatable(resumen_media)

cat("游늷Tabla de promedios por cluster ")
datatable(resumen_media)


```

Se observa que el grupo 1 presenta los menores promedios en la mayor칤a de los indicadores, destac치ndose por su baja productividad y menor impacto de sus publicaciones. Adem치s, el grupo 2 tiene los valores m치s altos en impacto normalizado y excelencia con liderazgol. Por otro lado, el grupo 3 es el m치s productivo con una diferencia bastante significativa y publicaciones en revistas de alto prestigio. Esto sugiere que el grupo 1 est치 m치s orientado a la ense침anza, mientras que el grupo 3 concentra las universidades m치s fuertes en investigaci칩n.

En cuanto a los grados de homogeneidad, el grupo 3 es el que mayor la tiene pues, tiene la mayor varianza en la mayoria de indicadores , en cuanto a los grupos 2 y 1 tienen una mayor dispersi칩n entre sus valores, es decir el grupo 3 agrupa instituciones m치s similares entre ellas, mientras los otros dos grupos presentan m치s diferencias en sus indicadores

```{r,echo=FALSE}
# ndefined游늷 8. Agregar los clusters al dataframe original
df_clustering$Cluster <- final_kmeans$cluster

# 游늷 9. Crear tablas de resumen

# Tabla con pa칤ses y su cluster asignado
tabla_Unipaises <- df_clustering %>% select(UniPais, Cluster)
tabla_paises <- df_clustering %>% select(Pais, Cluster)

library(DT)

# 游늷 13. C치lculo de varianza por cluster
resumen_varianza <- df_final %>%
  group_by(Cluster) %>%
  summarise(across(starts_with("SC"), var, .names = "{.col}"))

datatable(resumen_varianza)

cat("游늷Tabla de varianzas por cluster ")

```

## Punto 2

Ahora se van a construir los grupos de universidades seg칰n el indicador SC utilizando el 칤캼ndice de Hartigan.

En la siguiente tabla se muestran los valores del 칤ndice de Hartigan para diferentes n칰meros de grupos

```{r,echo=FALSE,warning=FALSE,message=FALSE}
library(NbClust)
library(readxl)
library(dplyr)
library(factoextra)
library(clusterCrit)
library(ggplot2)
library(openxlsx)
library(kableExtra)

# 游늷 1. Leer el archivo Excel
data <- read.csv2("C:/Users/fabia/OneDrive - Universidad Nacional de Colombia/UNAL/Descriptiva multivariada/Talleres/Recopilaci칩n/Bases de datos/r14_Sci_Qs_Webometrics.csv", sep = ";")

# 游늷 2. Reemplazar NA por 0 en las columnas num칠ricas
data <- data %>% mutate(across(where(is.numeric), ~ifelse(is.na(.), 0, .)))

# 游늷 3. Seleccionar solo PAIS, UniPais y columnas que inician con "SC"
cols_sc <- grep("^SC", names(data), value = TRUE)
data_selected <- data[, c("Pais", "UniPais", cols_sc)]

# 游늷 4. Remover columnas categ칩ricas (PAIS y UniPais) para el clustering
data_clustering <- data_selected[, cols_sc]

# 游늷 5. Estandarizar los datos
data_scaled <- scale(data_clustering)

# 游늷 6. Aplicar NbClust con el criterio de Hartigan
set.seed(123)  # Para reproducibilidad
result <- NbClust(data_scaled, distance = "euclidean", min.nc = 2, max.nc = 10, method = "kmeans", index = "hartigan")

# 游늷 7. Extraer el n칰mero 칩ptimo de clusters
optimal_k <- result$Best.nc[1]

# 游늷 8. Mostrar resultado
cat("\nEl n칰mero 칩ptimo de clusters seg칰n el criterio de Hartigan es:", optimal_k, "\n")

# 游늷 9. Crear una tabla con los valores del 칤ndice de Hartigan
hartigan_values <- data.frame(
  "N칰mero de grupos" = 2:10,
  "칈ndice Hartigan" = result$All.index
)

# 游늷 10. Imprimir la tabla en formato bonito
kable(hartigan_values, format = "html") %>%
  kable_styling(bootstrap_options = c("striped", "hover", "condensed", "responsive"))


```

Aqu칤 podemos evidenciar que el n칰mero 칩ptimo de grupos seg칰n el 칤ndice de Hartigan es 3, ya que del grupo 2 al 3 hay un salto muy grande (aprox 30) y a partir de ah칤 se puede decir que se estabiliza la variaci칩n de los grupos.

```{r,echo=FALSE}
#Gr치fico
colnames(hartigan_values) <- c("Num_Grupos", "Indice_Hartigan")

ggplot(hartigan_values, aes(x = Num_Grupos, y = Indice_Hartigan)) +
  geom_point(size = 3) +
  geom_line() +
  geom_text(aes(label = Num_Grupos), vjust = -0.5, size = 5) +
  theme_minimal() +
  labs(title = "Valor del 칈ndice de Hartigan por N칰mero de Grupos",
       x = "N칰mero de grupos",
       y = "Valor del 칈ndice de Hartigan")


```

En la siguiente tabla se muestra la clasificaci칩n de las universidadespor cada grupo seg칰n el 칤ndice de Hartigan, resalta que en el grupo 1 solo est치 la Universidad de Sao Pablo (USP), ya que, en la mayori칤a de indicadores del SC tiene los puntajes m치s altos y lejanos con respecto a los dem치s, en el grupo 2 es치n las universidades top de latino am칠rica con alto impacto en sus investigaciones, en cuanto a los grupos 3 y 4 tienen puntajes m치s diversos lo que sugiere un menor grado de productividad en investigaci칩n cient칤fica.

```{r,echo=FALSE}
# Asignar los datos a los clusters 칩ptimos
set.seed(123)
kmeans_result <- kmeans(data_clustering, centers = optimal_k, nstart = 25)

# Agregar la asignaci칩n de clusters a los datos originales
data_selected$Cluster <- kmeans_result$cluster

# Crear tabla de UniPais con sus clusters asignados
tabla_unipais_cluster <- data_selected %>% select(UniPais, Cluster)
tabla_pais_cluster <- data_selected %>% select(Pais, Cluster)

# Mostrar la tabla en un formato bonito si usas R Markdown
library(DT)

cat("游늷 Tabla: Universidades y sus Clusters\n")
datatable(tabla_unipais_cluster)

cat("游늷 Tabla: Pa칤ses y sus Clusters\n")
datatable(tabla_pais_cluster)

```

En la siguiente tabla de medias se puede ver que el grupo 1 presenta los mejores valores, lo que indica que las universidades pertenecientes a este grupo (solo USP) presentan caracter칤sticas muy destacadas en productividad, colaboraci칩n internacional, etc, por otro lado el grupo 2 tiene valores intermedios y el grupo 3 presenta los puntajes m치s bajos lo que se traduce en desempe침os inferiores con respecto a las universidades de los otros grupos

```{r,echo=FALSE}
# Calcular los promedios por cluster
promedios_por_cluster <- aggregate(. ~ Cluster, data = data_selected[, c(cols_sc, "Cluster")],
                                   FUN = mean)

# Opcional: Mostrar las tablas en un formato bonito si usas R Markdown
kable(promedios_por_cluster, caption = "Promedios de cada variable por cluster")
```

En la homogeneidad se tiene que el grupo 3 es el m치s disperso por sus altos valores de varianza en los indicadores, aunque menor que el 3, en cuanto al grupo 2 sus varianzas son m치s bajas asi que presenta una mayor similitud en el rendimiento de sus universidades, y el grupo 1 no tiene varianza porque solo est치 una universidad.

```{r,echo=FALSE}
# Calcular las varianzas por cluster
varianzas_por_cluster <- aggregate(. ~ Cluster, data = data_selected[, c(cols_sc, "Cluster")], FUN = var)
kable(varianzas_por_cluster, caption = "Varianzas de cada variable por cluster")
```



## Punto 3

Observemos las tablas de c칩mo se dividen por paises los clusters para entender

```{r,echo=FALSE}
tabla_Unipaises <- df_clustering %>% select(UniPais, Cluster)
tabla_Unipaises2 <- data_selected %>% select(UniPais, Cluster)

tabla_UnipaisesU <- cbind(tabla_Unipaises, tabla_Unipaises2)

datatable(tabla_UnipaisesU)
```

La primera diferencia notabla es que en el indicador de Carlinski-Harabasz hay 3 clusters, mientras tanto en el indicador de Hartigan hay 4, tambi칠n que la mayor칤a de universidades termin칩 en lugares diferentes a excepci칩n de algunas que se mantienen, pero en general su cambio fue notable.

Ahora veamos los promedios.

```{r,echo=FALSE}
datatable(resumen_media)
datatable(promedios_por_cluster)
```

Observamos que se ve mejor explicada en el indicador de Carlinski-Harabasz ya que tiene valores que tienen un sentido para lo que estamos haciendo ya que no hay valores tan desproporcionados excepto en productividad, mientras tanto en el indicador de Hartigan vemos que si tiene una desproporci칩n en el ranking de la instituci칩n en Am칠rica Latina, ranking de la instituci칩n en Iberoam칠rica, ranking de la instituci칩n en su pa칤s y en su productividad. En los otros brinda informaci칩n m치s clara de qu칠 grupos de universidades pueden ser mejor que otras.

```{r,echo=FALSE}
datatable(resumen_varianza)
datatable(varianzas_por_cluster)
```

En la varianza podemos ver algo muy parecido a lo que pasaba con el promedio con las proporciones manejadas en cada cluster.

## Punto 4

Se realizara el agrupamiento para el ranking QS

### Punto 4 - Carlinski-Harabasz

```{r,echo=FALSE}
#Cargar datos desde Excel
df <- read.csv2("C:/Users/fabia/OneDrive - Universidad Nacional de Colombia/UNAL/Descriptiva multivariada/Talleres/Recopilaci칩n/Bases de datos/r14_Sci_Qs_Webometrics.csv", sep = ";")

#Reemplazar NA por la media de cada columna (en caso de que haya quedado alguno)
df <- df %>% mutate(across(where(is.numeric), ~ifelse(is.na(.), mean(., na.rm = TRUE), .)))

#Seleccionar solo las columnas que comienzan con "QS" y las columnas "Pais" y "UniPais"
df_clustering <- df %>% select(Pais, UniPais, starts_with("QS"))

# Convertir columnas "QS" a num칠ricas
df_clustering <- df_clustering %>%
  mutate(across(starts_with("QS"), ~ as.numeric(gsub("[^0-9.]", "", .))))

#Reemplazar NA por la media de cada columna (en caso de que haya quedado alguno)
df_clustering <- df_clustering %>% mutate(across(where(is.numeric), ~ifelse(is.na(.), mean(., na.rm = TRUE), .)))

#Normalizar los datos num칠ricos
df_scaled <- df_clustering %>% select(starts_with("QS")) %>% scale()

df_scaled <- df_scaled %>%
  as.data.frame() %>%
  mutate(across(everything(), ~ ifelse(is.na(.) | is.nan(.) | is.infinite(.), mean(., na.rm = TRUE), .)))
```

Determinar el n칰mero 칩ptimo de clusters usando el 칤ndice de Cali켻ski-Harabasz, el nos indica que dos clusters son los optimos.


```{r,echo=FALSE}
set.seed(42)
res <- NbClust(df_scaled, distance = "euclidean", min.nc = 2, max.nc = 10, method = "kmeans", index = "ch")

# Extraer el n칰mero 칩ptimo de clusters
k_optimo <- as.numeric(res$Best.nc[1])
print(paste("N칰mero 칩ptimo de clusters seg칰n CH Index:", k_optimo))

# Extraer valores del 칤ndice para cada K
ch_values <- res$All.index
k_values <- 2:10
```

En la siguiente tabla vemos los valores de K y sus respectivos 칤ndices CH

```{r,echo=FALSE}
tabla_ch <- data.frame(Clusters = k_values, CH_Index = ch_values)

# Mostrar la tabla en la consola
datatable(tabla_ch)
```


Gr치fico del 칤ndice de Cali켻ski-Harabasz

Vemos que es suficiente ver que con dos grupos, recogen la informaci칩n de los datos

```{r,echo=FALSE}
plot(k_values, ch_values, type = "b", pch = 19, col = "blue",
     xlab = "N칰mero de Clusters (K)", ylab = "칈ndice de Cali켻ski-Harabasz",
     main = "Selecci칩n de K usando CH Index",
     xaxt = "n")

axis(1, at = k_values, labels = k_values) # A침ade los 10 valores en el eje X

# A침adir los valores de K sobre cada punto
text(k_values, ch_values, labels = k_values, pos = 3, col = "red", cex = 0.8)

#Aplicar K-means con el n칰mero 칩ptimo de clusters
set.seed(42)
final_kmeans <- kmeans(df_scaled, centers = k_optimo, nstart = 25)

#Agregar los clusters al dataframe original
df_clustering$Cluster <- final_kmeans$cluster
```

Crear tablas de resumen

```{r,echo=FALSE}
# Tabla con pa칤ses y su cluster asignado
tabla_Unipaises <- df_clustering %>% select(UniPais, Cluster)
tabla_paises <- df_clustering %>% select(Pais, Cluster)

# Tabla de promedios por cluster
resumen_media <- df_clustering %>%
  group_by(Cluster) %>%
  summarise(across(starts_with("QS"), mean, .names = "{.col}"))

# Tabla de varianzas por cluster
resumen_varianza <- df_clustering %>%
  group_by(Cluster) %>%
  summarise(across(starts_with("QS"), var, .names = "{.col}"))
```

Media de los grupos.

```{r,echo=FALSE}
datatable(resumen_media)
```

Varianza de los grupos. 

```{r,echo=FALSE}
datatable(resumen_varianza)
```

### Punto 4 - Hartigan

Reutilizando la base anterior df seleccionamos solo PAIS, Unipais y columnas que inician con "QS"

```{r,echo=FALSE}
cols_qs <- grep("^QS", names(df), value = TRUE)
data_selected <- df[, c("Pais", "UniPais", cols_qs)]

# Convertir columnas "QS" a num칠ricas
data_selected <- data_selected %>%
  mutate(across(starts_with("QS"), ~ as.numeric(gsub("[^0-9.]", "", .))))

# Reemplazar valores faltantes con la media de cada columna
for (col in cols_qs) {
  data_selected[[col]][is.na(data_selected[[col]])] <- mean(data_selected[[col]], na.rm = TRUE)
}

# Remover columnas categ칩ricas (PAIS y Unipais) para el clustering
data_clustering <- data_selected[, cols_qs]
```

Aplicar NbClust con el criterio de Hartigan

```{r,echo=FALSE}
set.seed(123)  # Para reproducibilidad
result <- NbClust(data_clustering, distance = "euclidean", min.nc = 2, max.nc = 10, method = "kmeans", index = "hartigan")

# Extraer el n칰mero 칩ptimo de clusters
optimal_k <- result$Best.nc[1]

# Mostrar resultado
cat("\nEl n칰mero 칩ptimo de clusters seg칰n el criterio de Hartigan es:", optimal_k, "\n")
```

Crear una tabla con los valores del 칤ndice de Hartigan

```{r,echo=FALSE}
hartigan_values <- data.frame(
  "N칰mero de grupos" = 2:10,
  "칈ndice Hartigan" = result$All.index
)

# Imprimir la tabla
datatable(hartigan_values)
```

Gr치fico

```{r,echo=FALSE}
colnames(hartigan_values) <- c("Num_Grupos", "Indice_Hartigan")

ggplot(hartigan_values, aes(x = Num_Grupos, y = Indice_Hartigan)) +
  geom_point(size = 3) +
  geom_line() +
  geom_text(aes(label = Num_Grupos), vjust = -0.5, size = 5) +
  theme_minimal() +
  labs(title = "Valor del 칈ndice de Hartigan por N칰mero de Grupos",
       x = "N칰mero de grupos",
       y = "Valor del 칈ndice de Hartigan")
```

```{r}
#Mostrar tabla
kable(hartigan_values, caption = "Valores del 칤ndice de Hartigan por n칰mero de grupos")
```

Mostrar tablas de promedios y varianzas

```{r,echo=FALSE}
# Asignar los datos a los clusters 칩ptimos
set.seed(123)
kmeans_result <- kmeans(data_clustering, centers = optimal_k, nstart = 25)

# Agregar la asignaci칩n de clusters a los datos originales
data_selected$Cluster <- kmeans_result$cluster

# Calcular los promedios por cluster
promedios_por_cluster <- aggregate(. ~ Cluster, data = data_selected[, c(cols_qs, "Cluster")], FUN = mean)

# Calcular las varianzas por cluster
varianzas_por_cluster <- aggregate(. ~ Cluster, data = data_selected[, c(cols_qs, "Cluster")], FUN = var)
```

```{r,echo=FALSE}
kable(promedios_por_cluster, caption = "Promedios de cada variable por cluster")
```

```{r,echo=FALSE}
kable(varianzas_por_cluster, caption = "Varianzas de cada variable por cluster")
```


## Punto 5

```{r, echo=FALSE}
R14 <- read.csv2("C:/Users/fabia/OneDrive - Universidad Nacional de Colombia/UNAL/Descriptiva multivariada/Talleres/Recopilaci칩n/Bases de datos/r14_Sci_Qs_Webometrics.csv", sep = ";")
SC <- R14[ ,c(2,17:24)]
SC[is.na(SC)] <- 0


SC <- SC %>%
group_by(Pais) %>%
summarize(across(1:8, mean))
  

SC <- as.data.frame(SC)
rownames(SC) <- SC$Pais
SC <- SC[ ,-1]
SC <- scale(SC)
colnames(SC) <- c("Productividad", "Colaboraci칩n interciol", "Impacto normalizado", "Publicaciones de alta calidad", "Indice de especializaci칩n", "Indice de excelencia", "Liderazgo cient칤fico", "Excelencia con liderazgo")



kable(round(SC,4), format = "html", booktabs = T, align = 'c') %>%
  kable_styling(latex_options = c("striped", "scale_down", 
                                  "hold_position"))


```

```{r, echo=FALSE}
require(FactoMineR)
ACPQS <- PCA(SC, graph = F)
```


```{r, echo=FALSE}
kable(round(ACPQS$eig,4), format = "html", booktabs = T, 
      align = 'c', col.names = c("Valor propio", "Porcentaje varianza", 
                                 "Porcentaje varianza acumulado")) %>%
  kable_styling(latex_options = c("striped", "scale_down", 
                                  "hold_position")) 


```
```{r, echo=FALSE}
ACPQS <- PCA(SC, graph = F, ncp = 2)
HCPC <- HCPC(ACPQS, nb.clust = -1, min = 2, max = 5, graph = F)


```

```{r, echo=FALSE}
kable(HCPC$data.clust, format = "html", booktabs = T, align = 'c') %>%
  kable_styling(latex_options = c("striped", "scale_down", 
                                  "hold_position"))

```
```{r, echo=FALSE}
# Gr치fico Dendograma
plot.HCPC(HCPC, axes = c(1,2), choice = "tree", title = "Agrupamiento
          Jer치rquico")

```
```{r, echo=FALSE}
# Plano factorial
fviz_cluster(HCPC, repel = TRUE, main = "Grupos en el plano factorial", 
             xlab = "Dimensi칩n 1 (35.7%)", ylab = "Dimensi칩n 2 (20.8%)",
             ellipse.type = "norm", ellipse.alpha = 0.2, shape = 20,
             pointsize = 1)


```



Al analizar la gr치fica, podemos determinar que dentro de cada grupo se observa una dispersi칩n notable. Esto refleja que, a pesar de las similitudes generales que justifican su agrupaci칩n (similitud en sus indicadores), existen diferencias internas significativas. Esta variabilidad sugiere que, aunque los pa칤ses comparten patrones amplios, tambi칠n presentan particularidades o matices que los distinguen dentro de su propio grupo.

Un ejemplo que podemos visualizar en el dendrograma es el del grupo 2. Pa칤ses como Brasil y Chile forman parte de este grupo, pero presentan diferencias internas a pesar de estar agrupados por sus grandes similitudes. Esto confirma que, aunque dos objetos se encuentren en el mismo grupo, no son del todo iguales. 


## Punto 6

Construir una agrupaci칩n jer치rquica por pa칤ses utilizando la salida del PCA con los indicadores del Qs, tipificar los grupos como en el ejemplo 1.12.1.

```{r,echo=FALSE,message=FALSE,warning=FALSE}

library(readxl)
library(dplyr)
library(tidyr)
library(NbClust)
library(kableExtra)
library(FactoMineR)
library(factoextra)


Rankings <- read.csv2("C:/Users/fabia/OneDrive - Universidad Nacional de Colombia/UNAL/Descriptiva multivariada/Talleres/Recopilaci칩n/Bases de datos/r14_Sci_Qs_Webometrics.csv", sep = ";")

RankingQS <- Rankings[ ,c(2,9:15)]

RankingQS[is.na(RankingQS)] <- 0

RankingQS <- RankingQS %>%
             group_by(Pais) %>%
             summarize(across(1:7, mean))

RankingQS <- as.data.frame(RankingQS)

rownames(RankingQS) <- RankingQS$Pais
RankingQS <- RankingQS[ ,-1]
RankingQS <- scale(RankingQS)

colnames(RankingQS) <- c("Reputaci칩n Acad칠mica", "Reputaci칩n entre 
                         empleadores", "Estudiantes por profesor", "Art칤culos
                         por docente", "Citas por art칤culo", "Docentes con
                         doctorado", "Impacto web")

kable(round(RankingQS,4), format = "html", booktabs = T, align = 'c') %>%
      kable_styling(latex_options = c("striped", "scale_down", 
                                      "hold_position")) 
```

```{r,echo=FALSE}

ACPQS <- PCA(RankingQS, graph = F)

kable(round(ACPQS$eig,4), format = "html", booktabs = T, 
      align = 'c', col.names = c("Valor propio", "Porcentaje varianza", 
                                 "Porcentaje varianza acumulado")) %>%
      kable_styling(latex_options = c("striped", "scale_down", 
                                  "hold_position")) 
```

```{r, fig.width = 10, fig.height = 7, dpi = 300,echo=FALSE}

ACPQS <- PCA(RankingQS, graph = F, ncp = 2)

HCPC <- HCPC(ACPQS, nb.clust = -1, min = 2, max = 5, graph = F)

kable(HCPC$data.clust, format = "html", booktabs = T, align = 'c') %>%
      kable_styling(latex_options = c("striped", "scale_down", 
                                      "hold_position"))
```

```{r,echo=FALSE}


plot.HCPC(HCPC, axes = c(1,2), choice = "tree", title = "Agrupamiento
          Jer치rquico")
```

```{r, fig.width = 10, fig.height = 7, dpi = 300, echo=FALSE}

fviz_cluster(HCPC, repel = TRUE, main = "Grupos en el plano actorial", 
             xlab = "Dimensi칩n 1 (35.7%)", ylab = "Dimensi칩n 2 (20.8%)",
             ellipse.type = "confidence", ellipse.alpha = 0.2, shape = 20,
             pointsize = 1)
```

Los resultados de la gr치fica muestran que los pa칤ses dentro de cada grupo tienden a agruparse en regiones cercanas del espacio factorial, lo que indica similitudes en varios indicadores del ranking QS. Sin embargo, a diferencia de otros an치lisis, los grupos no est치n estrictamente separados en cuadrantes distintos, lo que sugiere que no existen fronteras r칤gidas entre ellos y que algunos pa칤ses pueden compartir caracter칤sticas similares pese a pertenecer a distintos grupos.

Dentro de los grupos, se observa cierta dispersi칩n, lo que indica que, aunque los pa칤ses comparten similitudes generales, pueden presentar diferencias internas significativas en algunos indicadores clave. Estas diferencias pueden estar relacionadas con la reputaci칩n acad칠mica, la producci칩n cient칤fica o la internacionalizaci칩n, aspectos que influyen en la clasificaci칩n final de las universidades de cada pa칤s.

Adem치s, la posici칩n relativa de los pa칤ses sugiere que los factores utilizados capturan principalmente diferencias en t칠rminos de impacto de la investigaci칩n y prestigio institucional. Aquellos pa칤ses situados en posiciones extremas en los factores probablemente destacan o presentan rezagos en dimensiones espec칤ficas del ranking QS, como publicaciones altamente citadas o reputaci칩n acad칠mica.

En general, los resultados muestran que si bien existen patrones de agrupaci칩n, estos no son absolutamente r칤gidos, y la diferenciaci칩n entre pa칤ses depende en gran medida de c칩mo se combinan los distintos indicadores del ranking.

## Punto 7


### An치lisis del indicador SC para las universidades: 

El an치lisis del indicador SC mediante los criterios de Calinski-Harabasz y Hartigan revela diferencias significativas en la clasificaci칩n de universidades seg칰n su producci칩n cient칤fica. Mientras que el m칠todo de Calinski-Harabasz agrupa a las universidades en tres categor칤as seg칰n su impacto en la investigaci칩n, destacando un grupo intermedio con producci칩n significativa pero sin alcanzar a las universidades top, el 칤ndice de Hartigan resalta la excepcionalidad de la Universidad de S칚o Paulo (USP) al posicionarla en un grupo 칰nico debido a su destacado desempe침o.

Ambos enfoques muestran una clara diferenciaci칩n entre las universidades con alta productividad cient칤fica y colaboraci칩n internacional, aquellas con producci칩n intermedia, y las que tienen un menor 칠nfasis en la investigaci칩n. Esto sugiere que los criterios utilizados afectan la segmentaci칩n y ofrecen perspectivas complementarias sobre la estructura del sistema universitario en t칠rminos de impacto cient칤fico.




### An치lisis del indicador Qs: 

Utilizando el 칤ndice Carlinski-Harabasz vemos que son suficientes dos agrupaciones  y para el 칤ndice de Hartigan son suficientes cuatro agrupaciones. 
 
 
### Agrupaci칩n jer치rquica:
 
 
Para el an치lisis de indicador SC, en la gr치fica evidencia que, si bien los grupos se forman en funci칩n de similitudes en sus indicadores, existe una dispersi칩n notable dentro de cada uno. Esto indica que, aunque los pa칤ses comparten patrones generales, presentan diferencias internas significativas que los distinguen dentro de su propio grupo.

Un claro ejemplo de esto se observa en el grupo 2 del dendrograma, donde pa칤ses como Brasil y Chile comparten grandes similitudes pero tambi칠n muestran particularidades que los diferencian. Esto confirma que pertenecer al mismo grupo no implica homogeneidad absoluta, sino m치s bien una proximidad relativa en ciertos aspectos clave.




Los resultados de la gr치fica indican que los pa칤ses dentro de cada grupo tienden a ubicarse en regiones cercanas dentro del espacio factorial, reflejando similitudes en varios indicadores del ranking QS. No obstante, la ausencia de una separaci칩n estricta entre cuadrantes sugiere que las fronteras entre los grupos no son r칤gidas. Esto implica que algunos pa칤ses pueden compartir caracter칤sticas similares a pesar de pertenecer a distintos grupos, evidenciando una continuidad en lugar de una segmentaci칩n tajante en su clasificaci칩n.